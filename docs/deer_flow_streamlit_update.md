# Deer-flow Streamlit UI Update

## Overview

Updated the Streamlit interface for Deer-flow agents to provide a user experience closer to deer-flow's native UI, with relaxed CLI constraints and enhanced capabilities in the web context.

**âœ¨ NEW: File I/O Support** - Now includes `ConfigThreadDataMiddleware` (from genai-tk) to enable Python-based file I/O skills (ppt-generation, chart-visualization, etc.) with automatic workspace management and file downloads!

**Note:** This middleware is NOT Streamlit-specific and can be used in CLI, FastAPI, or any LangGraph application!

## Key Changes

### 1. **Mode Selection**

Added support for all four deer-flow modes:
- **Flash** (âš¡) - Fast responses, minimal overhead
- **Thinking** (ðŸ§ ) - Reasoning enabled, structured analysis  
- **Pro** (ðŸŽ¯) - Planning + thinking, complex tasks
- **Ultra** (ðŸš€) - All features enabled, maximum capability

Mode selector in sidebar allows users to choose between speed and capability. Default mode comes from profile configuration but can be overridden.

### 2. **Interactive Mode = True**

Now uses `interactive_mode=True` when creating agents since we're in a web UI context:
```python
agent = create_deer_flow_agent_simple(
    profile=profile,
    llm=llm,
    checkpointer=checkpointer,
    trace_middleware=trace_mw,
    interactive_mode=True,  # Web UI has more context than CLI
)
```

This enables more middlewares compared to CLI mode, particularly:
- ClarificationMiddleware for interactive clarifications 
- Potentially better file I/O support (though still limited vs. native deer-flow)

### 3. **Command Support**

Added command handling similar to CLI:
- `/help` - Show help information with commands and tips
- `/info` - Display current agent configuration (profile, mode, MCP servers, thread ID)
- `/clear` - Clear conversation history and traces
- `/trace` - Link to LangSmith for execution traces

Commands are documented in sidebar expander and chat input placeholder.

### 4. **Enhanced Profile Display**

Improved profile information in sidebar:
- **Mode indicator** - Shows current mode with icon
- **Feature badges** - Dynamic badges based on mode and profile capabilities
- **Skills information** - Shows skill count and directories being loaded
- **Better organization** - Cleaner layout with better visual hierarchy
- **Clickable examples** - Examples now use buttons instead of code blocks for easy execution

### 5. **Better State Management**

Enhanced session state to track:
- `df_agent_mode` - Currently selected mode
- `df_show_help` - Help display flag
- `df_show_info` - Info display flag  
- `df_example_input` - Example query clicked from sidebar

Mode changes trigger agent recreation to apply new configuration.

### 6. **Improved User Feedback**

- Status messages during agent creation show selected mode
- Better error messages with tracebacks
- Help and info displayed in nice formatted containers
- Mode descriptions shown in selector for guidance

### 7. **ConfigThreadDataMiddleware Implementation** âœ¨ NEW

Implemented generic middleware (in genai-tk) to enable Python-based file I/O skills without deer-flow's full infrastructure:

**Features:**
- âœ… Creates workspace directories: `.deer-flow/threads/{thread_id}/user-data/{workspace,uploads,outputs}`
- âœ… Gets thread_id from LangGraph's config (no runtime.context needed!)
- âœ… Adds `state["thread_data"]` with paths for skills to use
- âœ… Works with Python-based skills (ppt-generation, chart-visualization, csv-operations)
- âœ… Works in **any context**: Streamlit, CLI, FastAPI, Jupyter, etc.
- âœ… Automatic file browser in sidebar with download buttons (Streamlit)
- âœ… Shows file size, path, and modification time
- âœ… Workspace cleanup utilities included

**Location:** `genai_tk.extra.agents.deer_flow.config_thread_data_middleware.ConfigThreadDataMiddleware`

**Technical Solution:**
```python
# Instead of runtime.context.get("thread_id") which isn't available,
# we use LangGraph's config which IS available everywhere:
thread_id = runtime.config.get("configurable", {}).get("thread_id")

# This allows skills to work normally:
workspace = state["thread_data"]["workspace_path"]
output_file = os.path.join(workspace, "presentation.pptx")
prs.save(output_file)
```

**Usage in ANY application:**
```python
from genai_tk.extra.agents.deer_flow.config_thread_data_middleware import ConfigThreadDataMiddleware
from genai_tk.extra.agents.deer_flow.agent import create_deer_flow_agent_simple

# Create middleware (works in CLI, Streamlit, FastAPI, etc.)
thread_data_mw = ConfigThreadDataMiddleware()

# Pass to agent creation
agent = create_deer_flow_agent_simple(
    profile=profile,
    llm=llm,
    thread_data_middleware=thread_data_mw,  # Enable file I/O!
)
```

**UI Components (Streamlit):**
- File browser in sidebar shows generated files
- Download buttons for each file
- Shows file info (size, relative path)
- Displays workspace location
- Auto-refreshes when new files are created

**Limitations:**
- âŒ Does NOT enable bash/docker tools (those require SandboxProvider with container infrastructure)
- âœ… DOES enable all Python file I/O skills that run in the same process

## File Structure

```python
# Session State
- df_agent_mode: Current mode (flash/thinking/pro/ultra)
- df_show_help: Flag to display help panel
- df_show_info: Flag to display agent info
- df_thread_data_mw: ConfigThreadDataMiddleware instance (from genai-tk)
- df_example_input: Example query clicked from sidebar

# Functions
- initialize_session_state(): Added mode, display flags, middleware
- load_profiles(): Now includes mode, skills, skill_directories
- create_agent_for_profile(): Takes mode_override, uses interactive_mode=True, adds thread_data_mw
- display_sidebar(): Returns (profile_name, mode), adds mode selector, shows workspace files
- display_workspace_files(): File browser with download buttons
- main(): Handles commands, mode changes, example inputs

# Middleware Module (moved to genai-tk)
- genai_tk/extra/agents/deer_flow/config_thread_data_middleware.py: Generic middleware for any LangGraph app
```

## Differences from CLI

| Feature | CLI | Streamlit UI |
|---------|-----|--------------|
| Interactive mode | False (except chat) | True (always) |
| Middlewares | 2-3 active | More active (including Clarification) |
| ThreadDataMiddleware | âŒ Disabled | âœ… ConfigThreadDataMiddleware (from genai-tk) |
| Python file I/O skills | âŒ Limited | âœ… Fully supported |
| Workspace file browser | N/A | âœ… With downloads |
| Bash/docker tools | âŒ Disabled | âŒ Not supported |
| Mode selection | Command-line flag | Interactive selector |
| Examples | Copy/paste | Click to send |
| Commands | Prompt-based | Input-based |
| Traces | Console output | Visual panels |
| Profile switching | Restart needed | Live switching |

## Remaining Limitations

âœ… **SOLVED: ThreadDataMiddleware** - Now implemented as `ConfigThreadDataMiddleware` in genai-tk!

**This solution works in ANY LangGraph application:**
- âœ… Streamlit UI
- âœ… CLI interface  
- âœ… FastAPI servers
- âœ… Jupyter notebooks
- âœ… Any Python application using LangGraph

Still limited:

Still limited:

- **No AioSandboxProvider** - Can't run bash/docker tools without container infrastructure
- **Bash tools require containers** - Would need `StreamlitSandboxProvider` (complex, security concerns)
- **Memory persistence** - Limited to session, not cross-session like native deer-flow (could be extended)

### Core Issue: Sandbox Container Support

**What we solved:**
- âœ… ThreadDataMiddleware â†’ StreamlitThreadDataMiddleware (gets thread_id from config instead of runtime.context)
- âœ… Python file I/O skills now work perfectly
- âœ… Workspace management and file downloads

**What remains challenging:**
**What remains challenging:**

**AioSandboxProvider** (for bash/docker tools) also needs thread_id to mount workspace into containers:
```python
# Also needs thread_id to mount workspace into sandbox container
# (Could potentially be solved the same way as ThreadDataMiddleware!)
thread_id = runtime.config.get("configurable", {}).get("thread_id")
thread_dir = Path(base_dir) / ".deer-flow/threads" / thread_id / "user-data"

# Creates same directories and mounts them into Docker/K8s container
mounts = [
    (str(thread_dir / "workspace"), "/virt/workspace", False),
    (str(thread_dir / "uploads"), "/virt/uploads", False),
    (str(thread_dir / "outputs"), "/virt/outputs", False),
]
# But then needs to manage Docker containers, networking, isolation, etc.
```

**Complexity of implementing StreamlitSandboxProvider:**
- Need to spawn Docker containers per request
- Mount workspace directories into containers
- Handle container lifecycle (start, monitor, cleanup)
- Security implications of running arbitrary bash commands
- Resource management (container limits, cleanup)
- Networking and port management

This is significantly more complex than ThreadDataMiddleware and has security implications. For now, **Python-based file I/O skills are fully supported**, which covers most use cases. 

**Skill execution comparison:**

| Skill Type | Streamlit UI | Deer-flow Native |
|-------------|--------------|------------------|
| Python file I/O (pptx, csv, charts) | âœ… **Fully supported** | âœ… Supported |
| Web search, Q&A, reasoning | âœ… **Fully supported** | âœ… Supported |
| Bash commands | âŒ Not supported | âœ… Supported (container) |
| Docker tools | âŒ Not supported | âœ… Supported (nested containers) |
| External binaries (ffmpeg) | âŒ Not supported | âœ… Supported (container) |

### Recommendation

**Streamlit UI is now excellent for:**
- âœ… Research, Q&A, web search
- âœ… Advanced reasoning and planning
- âœ… **Python-based file I/O (ppt-generation, chart-visualization, data analysis)**
- âœ… MCP tool integration
- âœ… Interactive development and testing

**Use deer-flow native UI for:**
- Bash/shell command execution
- Docker-based tools
- External binary tools (ffmpeg, imagemagick, etc.)
- Maximum security isolation

## Usage

```bash
# From genai-blueprint directory
make webapp

# Or directly
streamlit run genai_blueprint/main/streamlit.py
```

Then navigate to "Demos > Deer-flow Agent" in the sidebar.

## Testing Checklist

### Basic Functionality
- [ ] Profile selection works and updates sidebar
- [ ] Mode selector changes take effect
- [ ] Commands (/help, /info, /clear, /trace) work correctly
- [ ] Example queries can be clicked and executed
- [ ] Agent creation succeeds with different modes
- [ ] Traces display correctly during execution
- [ ] Error handling shows helpful messages
- [ ] Mode changes trigger agent recreation
- [ ] Conversation history persists across queries
- [ ] Chat clearing works properly

### File I/O Features âœ¨ NEW
- [ ] Workspace directory is created (.deer-flow-streamlit/threads/{thread_id}/user-data/)
- [ ] File browser appears in sidebar after file generation
- [ ] Generated files show correct name, size, and path
- [ ] Download buttons work for each file
- [ ] Multiple files are displayed correctly
- [ ] Workspace path is shown at bottom of file list
- [ ] Files persist across agent invocations in same session
- [ ] New session gets new workspace directory

### Skills to Test
Try these skills that now work with file I/O support:
- [ ] `ppt-generation` - Creates PowerPoint presentations
- [ ] `chart-visualization` - Generates charts and saves to files  
- [ ] `csv-operations` - Reads/writes CSV files
- [ ] `data-analysis` - Analyzes data and saves reports

Example prompt: 
```
Create a PowerPoint presentation about Python programming with 3 slides: 
intro, key features, and conclusion.
```

## Next Steps

Potential future improvements:

### Implemented âœ…
1. ~~**Runtime context mocking**~~ â†’ **DONE!** ConfigThreadDataMiddleware uses LangGraph's config (in genai-tk)
2. ~~**Workspace directory creation**~~ â†’ **DONE!** Automatic workspace management
3. ~~**File browser UI**~~ â†’ **DONE!** Display and download files from workspace
4. ~~**Moved to genai-tk**~~ â†’ **DONE!** Middleware now available for CLI, FastAPI, any LangGraph app

### Future Enhancements
4. **File upload UI** - Allow users to upload files to the uploads directory
5. **Workspace selector** - Let users choose/manage multiple workspace directories
6. **Memory viewer** - Display conversation memory and summarization
7. **Skill browser** - Interactive skill discovery and documentation
8. **Trace visualization** - Enhanced trace display with graph visualization
9. **CLI file I/O** - Enable ConfigThreadDataMiddleware in deer-flow CLI commands
10. **StreamlitSandboxProvider** - Container support for bash tools (complex, lower priority)
10. **Workspace cleanup UI** - Button to clean up old thread directories

## Implementation Details

### StreamlitThreadDataMiddleware Architecture

### StreamlitThreadDataMiddleware Architecture

The middleware solves the runtime.context issue by using LangGraph's config which IS available:

```python
class ConfigThreadDataMiddleware:
    """Provides workspace paths without runtime.context dependency."""
    
    def before_agent(self, state, runtime):
        # Get thread_id from config instead of runtime.context
        # This works in CLI, Streamlit, FastAPI, anywhere!
        thread_id = runtime.config.get("configurable", {}).get("thread_id")
        
        # Create workspace directories
        paths = self._create_thread_directories(thread_id)
        
        # Add to state just like deer-flow's ThreadDataMiddleware
        return {"thread_data": paths}
```

**Key features:**
- Compatible with deer-flow's ThreadDataMiddleware state schema
- Falls back to "default" if no thread_id found
- Creates directories immediately (not lazy) for reliability
- Provides utility methods for file listing and cleanup
- Works with existing deer-flow skills without modification
- **Universal:** Works in any LangGraph application (not just Streamlit!)

**Directory structure:**
```
.deer-flow/
â””â”€â”€ threads/
    â””â”€â”€ {thread_id}/
        â””â”€â”€ user-data/
            â”œâ”€â”€ workspace/  # Main workspace for generated files
            â”œâ”€â”€ uploads/    # For user uploads (future)
            â””â”€â”€ outputs/    # Deprecated, use workspace
```

**Usage Examples:**

*In Streamlit (current):*
```python
from genai_tk.extra.agents.deer_flow.config_thread_data_middleware import ConfigThreadDataMiddleware

mw = ConfigThreadDataMiddleware()
agent = create_deer_flow_agent_simple(
    profile=profile,
    llm=llm,
    thread_data_middleware=mw,
)
```

*In CLI (future):*
```python
# Enable file I/O in CLI by passing the middleware
mw = ConfigThreadDataMiddleware()
agent = create_deer_flow_agent_simple(
    profile=profile,
    llm=llm,
    thread_data_middleware=mw,
    interactive_mode=False,  # CLI mode
)
```

*In FastAPI:*
```python
@app.post("/chat")
async def chat(request: ChatRequest):
    mw = ConfigThreadDataMiddleware
()
    agent = create_deer_flow_agent_simple(
        profile=profile,
        thread_data_middleware=mw,
    )
    # ... run agent ...
```

## Related Documentation

- [Deer-flow Runtime Context Solution](deer_flow_runtime_context_solution.md) - Deep dive into ThreadDataMiddleware/AioSandboxProvider and solutions
- [Deer-flow CLI Fix Summary](/home/tcl/prj/genai-tk/docs/deerflow_cli_fix_summary.md) - CLI limitations and middleware details
- [Deer-flow Agent Code](/home/tcl/prj/genai-tk/genai_tk/extra/agents/deer_flow/agent.py) - Core agent implementation
- [Deer-flow CLI Commands](/home/tcl/prj/genai-tk/genai_tk/extra/agents/deer_flow/cli_commands.py) - CLI implementation reference
